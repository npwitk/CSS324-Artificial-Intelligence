{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6884318",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cc509e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS is available\n"
     ]
    }
   ],
   "source": [
    "# Select proper device to do the training!\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"CUDA is available\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"MPS is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA is not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebcbbe5",
   "metadata": {},
   "source": [
    "# 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6ae1460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1301a755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "basic_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert PIL image to tensor\n",
    "    transforms.Lambda(lambda x: x / 255.0)  # Normalize pixel values to [0, 1]\n",
    "])\n",
    "\n",
    "# It is not necessary to flatten the image. (Wow, because we are going to use CNN ไงง)\n",
    "# Now it accepts 28x28x1 (grayscale image)\n",
    "batch_size = 64\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    transform=basic_transforms,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "# Split the train_dataset into train and validation sets\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "    train_dataset, [train_size, val_size]\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    transform=basic_transforms,\n",
    "    download=True\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d5c41d",
   "metadata": {},
   "source": [
    "# 2. Convolutional Neural Network\n",
    "## 2.1 LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aad94a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the original LeNet-5 architecture.\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5, padding=2) # (number of input channels, number of out channels = # kernels, kernal_size = 5x5, SAME convolution)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5, padding=0) # (, , , VALID convolution)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x): # x = 28*28*1\n",
    "        x = self.conv1(x) # 28*28*6\n",
    "        x = F.avg_pool2d(x, 2) # 14*14*6\n",
    "        x = self.conv2(x) # (14-5+1)*(14-5+1)*16 = 10*10*16\n",
    "        x = F.avg_pool2d(x, 2) # 5*5*16\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x) # 120\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x) # 84\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x) # 10\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9142da",
   "metadata": {},
   "source": [
    "### Training Loop with Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d403157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, loss_fn,\n",
    "                optimizer, epochs, device, scheduler=None,\n",
    "                early_stop=True, patience=5, min_delta=0.001,\n",
    "                model_name='best_model.pth'):\n",
    "    train_losses, val_losses = [], []\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss, train_steps = 0.0, 0\n",
    "        \n",
    "        for x_batch, y_batch in train_loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            y_pred = model(x_batch)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            # Update weights\n",
    "            optimizer.step()\n",
    "            \n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "            \n",
    "            # Accumulate loss\n",
    "            train_loss += loss.item()\n",
    "            train_steps += 1\n",
    "        \n",
    "        train_loss_avg = train_loss / train_steps\n",
    "        train_losses.append(train_loss_avg)\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        model.eval()\n",
    "        val_loss, val_steps = 0.0, 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch in val_loader:\n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                y_pred = model(x_batch)\n",
    "                loss = loss_fn(y_pred, y_batch)\n",
    "                val_loss += loss.item()\n",
    "                val_steps += 1\n",
    "        \n",
    "        val_loss_avg = val_loss / val_steps\n",
    "        val_losses.append(val_loss_avg)\n",
    "        \n",
    "        # Early stopping logic\n",
    "        if early_stop:\n",
    "            if val_loss_avg < best_val_loss - min_delta:\n",
    "                best_val_loss = val_loss_avg\n",
    "                patience_counter = 0\n",
    "                # Save the best model state\n",
    "                best_model_state = model.state_dict().copy()\n",
    "                print(f\"Epoch {epoch + 1:3d}/{epochs},\",\n",
    "                      f\"Loss: {train_loss_avg:.4f},\",\n",
    "                      f\"Validation Loss: {val_loss_avg:.4f} (Best)\")\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                print(f\"Epoch {epoch + 1:3d}/{epochs},\",\n",
    "                      f\"Loss: {train_loss_avg:.4f},\",\n",
    "                      f\"Validation Loss: {val_loss_avg:.4f}\",\n",
    "                      f\"(Patience: {patience_counter}/{patience})\")\n",
    "                \n",
    "                # Check for early stopping\n",
    "                if patience_counter >= patience:\n",
    "                    print(f\"\\nEarly stopping triggered at epoch {epoch + 1}\")\n",
    "                    print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "                    break\n",
    "        else:\n",
    "            print(f\"Epoch {epoch + 1:3d}/{epochs},\",\n",
    "                  f\"Loss: {train_loss_avg:.4f},\",\n",
    "                  f\"Validation Loss: {val_loss_avg:.4f}\")\n",
    "    \n",
    "    # Restore the best model state\n",
    "    if best_model_state is not None:\n",
    "        # Save the best model state to a file\n",
    "        torch.save(best_model_state, model_name)\n",
    "        model.load_state_dict(best_model_state)\n",
    "        print(\"Restored best model state\")\n",
    "    \n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f30ce3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, loss_fn, device):\n",
    "    model.eval()\n",
    "    test_loss, test_steps = 0.0, 0\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in test_loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            y_pred = model(x_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            test_loss += loss.item()\n",
    "            test_steps += 1\n",
    "            \n",
    "            preds = y_pred.argmax(dim=1)\n",
    "            correct_predictions += (preds == y_batch).sum().item()\n",
    "    \n",
    "    test_loss_avg = test_loss / test_steps\n",
    "    test_accuracy = correct_predictions / len(test_loader.dataset)\n",
    "    print(f\"Loss: {test_loss_avg:.4f}, Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcbb86b",
   "metadata": {},
   "source": [
    "### Training LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0303e4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1/100, Loss: 2.1861, Validation Loss: 1.3758 (Best)\n",
      "Epoch   2/100, Loss: 0.6724, Validation Loss: 0.5001 (Best)\n",
      "Epoch   3/100, Loss: 0.4319, Validation Loss: 0.3764 (Best)\n",
      "Epoch   4/100, Loss: 0.3347, Validation Loss: 0.3102 (Best)\n",
      "Epoch   5/100, Loss: 0.2715, Validation Loss: 0.2549 (Best)\n",
      "Epoch   6/100, Loss: 0.2302, Validation Loss: 0.2230 (Best)\n",
      "Epoch   7/100, Loss: 0.2036, Validation Loss: 0.2046 (Best)\n",
      "Epoch   8/100, Loss: 0.1858, Validation Loss: 0.1953 (Best)\n",
      "Epoch   9/100, Loss: 0.1712, Validation Loss: 0.1739 (Best)\n",
      "Epoch  10/100, Loss: 0.1610, Validation Loss: 0.1646 (Best)\n",
      "Epoch  11/100, Loss: 0.1511, Validation Loss: 0.1603 (Best)\n",
      "Epoch  12/100, Loss: 0.1429, Validation Loss: 0.1674 (Patience: 1/5)\n",
      "Epoch  13/100, Loss: 0.1362, Validation Loss: 0.1476 (Best)\n",
      "Epoch  14/100, Loss: 0.1319, Validation Loss: 0.1374 (Best)\n",
      "Epoch  15/100, Loss: 0.1246, Validation Loss: 0.1433 (Patience: 1/5)\n",
      "Epoch  16/100, Loss: 0.1195, Validation Loss: 0.1434 (Patience: 2/5)\n",
      "Epoch  17/100, Loss: 0.1143, Validation Loss: 0.1275 (Best)\n",
      "Epoch  18/100, Loss: 0.1099, Validation Loss: 0.1277 (Patience: 1/5)\n",
      "Epoch  19/100, Loss: 0.1050, Validation Loss: 0.1305 (Patience: 2/5)\n",
      "Epoch  20/100, Loss: 0.1002, Validation Loss: 0.1321 (Patience: 3/5)\n",
      "Epoch  21/100, Loss: 0.0958, Validation Loss: 0.1176 (Best)\n",
      "Epoch  22/100, Loss: 0.0925, Validation Loss: 0.1111 (Best)\n",
      "Epoch  23/100, Loss: 0.0886, Validation Loss: 0.1156 (Patience: 1/5)\n",
      "Epoch  24/100, Loss: 0.0847, Validation Loss: 0.1158 (Patience: 2/5)\n",
      "Epoch  25/100, Loss: 0.0841, Validation Loss: 0.1022 (Best)\n",
      "Epoch  26/100, Loss: 0.0801, Validation Loss: 0.1027 (Patience: 1/5)\n",
      "Epoch  27/100, Loss: 0.0765, Validation Loss: 0.1062 (Patience: 2/5)\n",
      "Epoch  28/100, Loss: 0.0758, Validation Loss: 0.1042 (Patience: 3/5)\n",
      "Epoch  29/100, Loss: 0.0721, Validation Loss: 0.0989 (Best)\n",
      "Epoch  30/100, Loss: 0.0719, Validation Loss: 0.0954 (Best)\n",
      "Epoch  31/100, Loss: 0.0694, Validation Loss: 0.1001 (Patience: 1/5)\n",
      "Epoch  32/100, Loss: 0.0666, Validation Loss: 0.1039 (Patience: 2/5)\n",
      "Epoch  33/100, Loss: 0.0652, Validation Loss: 0.0960 (Patience: 3/5)\n",
      "Epoch  34/100, Loss: 0.0640, Validation Loss: 0.0894 (Best)\n",
      "Epoch  35/100, Loss: 0.0619, Validation Loss: 0.0915 (Patience: 1/5)\n",
      "Epoch  36/100, Loss: 0.0593, Validation Loss: 0.0988 (Patience: 2/5)\n",
      "Epoch  37/100, Loss: 0.0569, Validation Loss: 0.0877 (Best)\n",
      "Epoch  38/100, Loss: 0.0584, Validation Loss: 0.0887 (Patience: 1/5)\n",
      "Epoch  39/100, Loss: 0.0565, Validation Loss: 0.0966 (Patience: 2/5)\n",
      "Epoch  40/100, Loss: 0.0543, Validation Loss: 0.0983 (Patience: 3/5)\n",
      "Epoch  41/100, Loss: 0.0526, Validation Loss: 0.0849 (Best)\n",
      "Epoch  42/100, Loss: 0.0525, Validation Loss: 0.0909 (Patience: 1/5)\n",
      "Epoch  43/100, Loss: 0.0509, Validation Loss: 0.0881 (Patience: 2/5)\n",
      "Epoch  44/100, Loss: 0.0496, Validation Loss: 0.0897 (Patience: 3/5)\n",
      "Epoch  45/100, Loss: 0.0483, Validation Loss: 0.0846 (Patience: 4/5)\n",
      "Epoch  46/100, Loss: 0.0472, Validation Loss: 0.0840 (Patience: 5/5)\n",
      "\n",
      "Early stopping triggered at epoch 46\n",
      "Best validation loss: 0.0849\n",
      "Restored best model state\n",
      "Evaluating on training set...\n",
      "Loss: 0.0404, Accuracy: 0.9877\n",
      "Evaluating on validation set...\n",
      "Loss: 0.0840, Accuracy: 0.9741\n",
      "Evaluating on test set...\n",
      "Loss: 0.0771, Accuracy: 0.9756\n"
     ]
    }
   ],
   "source": [
    "lenet = LeNet().to(device)\n",
    "epochs = 100\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lenet.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "\n",
    "train_losses, val_losses = train_model(\n",
    "    lenet, train_loader, val_loader,\n",
    "    loss_fn, optimizer, epochs, device, \n",
    "    scheduler=scheduler,\n",
    "    early_stop=True, \n",
    "    model_name='best_lenet.pth'\n",
    ")\n",
    "\n",
    "print(\"Evaluating on training set...\")\n",
    "evaluate_model(lenet, train_loader, loss_fn, device)\n",
    "print(\"Evaluating on validation set...\")\n",
    "evaluate_model(lenet, val_loader, loss_fn, device)\n",
    "print(\"Evaluating on test set...\")\n",
    "evaluate_model(lenet, test_loader, loss_fn, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7340f491",
   "metadata": {},
   "source": [
    "## 2.2 Custom CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb839f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, dropout_rate=0.25):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        \n",
    "        # Define the Convolutional Blocks\n",
    "        self.features = nn.Sequential(\n",
    "            # Conv Block 1: 28x28x1 -> 26x26x32 (from 28-3+1 = 26) -> 13x13x32\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=0),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            # Conv Block 2: 13x13x32 -> 11x11x64 -> 5x5x64\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=0),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            # Conv Block 3: 5x5x64 -> 3x3x128\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=0),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25)\n",
    "            # Note: Final output size after all conv/pool layers is 3x3x128\n",
    "        )\n",
    "        \n",
    "        # Define the Fully-Connected (Dense) Layers\n",
    "        self.classifier = nn.Sequential(\n",
    "            # Input size: 3*3*128 = 1152 features\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(3 * 3 * 128, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(256, 10)  # Output layer for 10 classes (digits 0-9)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a782b40d",
   "metadata": {},
   "source": [
    "### Training Custom CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95bc7d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1/100, Loss: 0.9967, Validation Loss: 0.3954 (Best)\n",
      "Epoch   2/100, Loss: 0.3575, Validation Loss: 0.1906 (Best)\n",
      "Epoch   3/100, Loss: 0.2232, Validation Loss: 0.1316 (Best)\n",
      "Epoch   4/100, Loss: 0.1661, Validation Loss: 0.1714 (Patience: 1/5)\n",
      "Epoch   5/100, Loss: 0.1325, Validation Loss: 0.0751 (Best)\n",
      "Epoch   6/100, Loss: 0.1158, Validation Loss: 0.0622 (Best)\n",
      "Epoch   7/100, Loss: 0.1006, Validation Loss: 0.0812 (Patience: 1/5)\n",
      "Epoch   8/100, Loss: 0.0914, Validation Loss: 0.0705 (Patience: 2/5)\n",
      "Epoch   9/100, Loss: 0.0840, Validation Loss: 0.0466 (Best)\n",
      "Epoch  10/100, Loss: 0.0783, Validation Loss: 0.0441 (Best)\n",
      "Epoch  11/100, Loss: 0.0730, Validation Loss: 0.0417 (Best)\n",
      "Epoch  12/100, Loss: 0.0683, Validation Loss: 0.0439 (Patience: 1/5)\n",
      "Epoch  13/100, Loss: 0.0663, Validation Loss: 0.0388 (Best)\n",
      "Epoch  14/100, Loss: 0.0620, Validation Loss: 0.0364 (Best)\n",
      "Epoch  15/100, Loss: 0.0593, Validation Loss: 0.0405 (Patience: 1/5)\n",
      "Epoch  16/100, Loss: 0.0554, Validation Loss: 0.0366 (Patience: 2/5)\n",
      "Epoch  17/100, Loss: 0.0551, Validation Loss: 0.0327 (Best)\n",
      "Epoch  18/100, Loss: 0.0529, Validation Loss: 0.0341 (Patience: 1/5)\n",
      "Epoch  19/100, Loss: 0.0527, Validation Loss: 0.0368 (Patience: 2/5)\n",
      "Epoch  20/100, Loss: 0.0501, Validation Loss: 0.0326 (Patience: 3/5)\n",
      "Epoch  21/100, Loss: 0.0493, Validation Loss: 0.0328 (Patience: 4/5)\n",
      "Epoch  22/100, Loss: 0.0477, Validation Loss: 0.0323 (Patience: 5/5)\n",
      "\n",
      "Early stopping triggered at epoch 22\n",
      "Best validation loss: 0.0327\n",
      "Restored best model state\n",
      "Evaluating on training set...\n",
      "Loss: 0.0176, Accuracy: 0.9947\n",
      "Evaluating on validation set...\n",
      "Loss: 0.0323, Accuracy: 0.9909\n",
      "Evaluating on test set...\n",
      "Loss: 0.0217, Accuracy: 0.9933\n"
     ]
    }
   ],
   "source": [
    "custom_cnn = CustomCNN().to(device)\n",
    "epochs = 100\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(custom_cnn.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "\n",
    "train_losses, val_losses = train_model(\n",
    "    custom_cnn, train_loader, val_loader,\n",
    "    loss_fn, optimizer, epochs, device, \n",
    "    scheduler=scheduler,\n",
    "    early_stop=True, \n",
    "    model_name='best_custom_cnn.pth'\n",
    ")\n",
    "\n",
    "print(\"Evaluating on training set...\")\n",
    "evaluate_model(custom_cnn, train_loader, loss_fn, device)\n",
    "print(\"Evaluating on validation set...\")\n",
    "evaluate_model(custom_cnn, val_loader, loss_fn, device)\n",
    "print(\"Evaluating on test set...\")\n",
    "evaluate_model(custom_cnn, test_loader, loss_fn, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cef7a4",
   "metadata": {},
   "source": [
    "# 3. Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97bc7008",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'catdog_X.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Cat-Dog Classification\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcatdog_X.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcatdog_y.pt\u001b[39m\u001b[38;5;124m'\u001b[39m, weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m D \u001b[38;5;241m=\u001b[39m TensorDataset(X, y)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch/serialization.py:1319\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1317\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1319\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1321\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1323\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch/serialization.py:659\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    658\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 659\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    660\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    661\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch/serialization.py:640\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 640\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'catdog_X.pt'"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cat-Dog Classification\n",
    "X = torch.load('catdog_X.pt', weights_only=True)\n",
    "y = torch.load('catdog_y.pt', weights_only=True)\n",
    "D = TensorDataset(X, y)\n",
    "\n",
    "catdog_train_set, catdog_val_set, catdog_test_set = random_split(\n",
    "    D, [0.7, 0.15, 0.15]\n",
    ")\n",
    "\n",
    "catdog_train_loader = DataLoader(catdog_train_set, batch_size=64, shuffle=True)\n",
    "catdog_val_loader = DataLoader(catdog_val_set, batch_size=64, shuffle=False)\n",
    "catdog_test_loader = DataLoader(catdog_test_set, batch_size=64, shuffle=False)\n",
    "\n",
    "# Show some images\n",
    "img_idx = [0, 1, 2, 3, 4, 12500, 12501, 12502, 12503, 12504]\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(X[img_idx[i]].permute(1, 2, 0))\n",
    "    plt.title(f\"Label: {y[img_idx[i]]}\")\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40ffac9",
   "metadata": {},
   "source": [
    "### Transfer Learning with ResNet18 (Frozen Layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ddbf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "\n",
    "# Freeze all parameters except the last layer\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "epochs = 100\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "\n",
    "train_losses, val_losses = train_model(\n",
    "    model, catdog_train_loader, catdog_val_loader,\n",
    "    loss_fn, optimizer, epochs, device, \n",
    "    scheduler=scheduler,\n",
    "    early_stop=True, \n",
    "    model_name='best_resnet18_catdog.pth'\n",
    ")\n",
    "\n",
    "print(\"Evaluating on training set...\")\n",
    "evaluate_model(model, catdog_train_loader, loss_fn, device)\n",
    "print(\"Evaluating on validation set...\")\n",
    "evaluate_model(model, catdog_val_loader, loss_fn, device)\n",
    "print(\"Evaluating on test set...\")\n",
    "evaluate_model(model, catdog_test_loader, loss_fn, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c83eb16",
   "metadata": {},
   "source": [
    "### Fine-tuning (Unfrozen Layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de26f44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze all parameters\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "optimizer = optim.Adam([\n",
    "    {'params': (p for n, p in model.named_parameters() if \"fc\" not in n),\n",
    "     'lr': 1e-5},\n",
    "    {'params': (p for n, p in model.named_parameters() if \"fc\" in n),\n",
    "     'lr': 1e-4}\n",
    "], weight_decay=0.001)\n",
    "\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "\n",
    "train_losses, val_losses = train_model(\n",
    "    model, catdog_train_loader, catdog_val_loader,\n",
    "    loss_fn, optimizer, epochs, device, \n",
    "    scheduler=scheduler,\n",
    "    early_stop=True, \n",
    "    model_name='best_resnet18_catdog.pth'\n",
    ")\n",
    "\n",
    "print(\"Evaluating on training set...\")\n",
    "evaluate_model(model, catdog_train_loader, loss_fn, device)\n",
    "print(\"Evaluating on validation set...\")\n",
    "evaluate_model(model, catdog_val_loader, loss_fn, device)\n",
    "print(\"Evaluating on test set...\")\n",
    "evaluate_model(model, catdog_test_loader, loss_fn, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
